{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installing required libraries"
      ],
      "metadata": {
        "id": "UUPfzg68MmXZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install tensorflow\n",
        "! pip install transformers"
      ],
      "metadata": {
        "id": "MapU8l_KCcIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing required libraries"
      ],
      "metadata": {
        "id": "qTTCXKGCMszA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "import numpy as np\n",
        "import requests\n",
        "import cv2\n",
        "import seaborn as sea\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from transformers import GPT2Tokenizer, GPT2Model\n",
        "# from tensorflow.keras import keras\n",
        "from keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "pKrG4NfhjYAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Dataset"
      ],
      "metadata": {
        "id": "9jlVFQAsMz1w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OI-2nM6jcduv"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/multimodal_test_public.tsv', delimiter='\\t')\n",
        "df = df.head(10000)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting labels from the dataset\n"
      ],
      "metadata": {
        "id": "J8_OFDwuNBbf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = df['2_way_label'].values"
      ],
      "metadata": {
        "id": "VEj5kPHPNE3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initializing the tokenizer and model for text processing\n"
      ],
      "metadata": {
        "id": "V_qxSFXINLGO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model = GPT2Model.from_pretrained('gpt2')"
      ],
      "metadata": {
        "id": "FvFTH0vNNRFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Splitting the dataset into training and testing sets\n"
      ],
      "metadata": {
        "id": "tZIxFWNgNYQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data, train_labels, test_labels = train_test_split(df[['clean_title','image_url','2_way_label']], labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "83I-LUXug3nf",
        "outputId": "08c02c11-58f6-4b95-99e7-a7380bb8db58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-aca51c15a852>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clean_title'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'image_url'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'2_way_label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function to get text embeddings using GPT2"
      ],
      "metadata": {
        "id": "Q05ItHbuNijZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_text_embedding(text):\n",
        "    tokenized_text = tokenizer.encode(text, return_tensors='pt', max_length=512, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        model_output = model(tokenized_text)\n",
        "    embedding = model_output.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "    return embedding"
      ],
      "metadata": {
        "id": "Bzuzh0fLvTlV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function to get image embeddings from a URL"
      ],
      "metadata": {
        "id": "7r4oGaNxNzcH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_image_embedding(url, target_size=(224, 224)):\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        image = cv2.imdecode(np.frombuffer(response.content, np.uint8), cv2.IMREAD_COLOR)\n",
        "\n",
        "        if image is None:\n",
        "            raise Exception(\"Failed to decode image from URL.\")\n",
        "\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        image = cv2.resize(image, target_size)\n",
        "        image_array = image.astype(np.float32) / 255.0\n",
        "        return image_array\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing image from URL {url}: {str(e)}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "oflks0hTzU6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function to get text and image embeddings and labels from dataframe"
      ],
      "metadata": {
        "id": "3ZIQLnIKOCRL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_text_embeddings_image_embeddings_labels(dataframe):\n",
        "    text_embeddings, image_embeddings, labels = [], [], []\n",
        "    for clean_title, image_url, label in zip(dataframe['clean_title'], dataframe['image_url'], dataframe['2_way_label']):\n",
        "        text_embedding = get_text_embedding(clean_title)\n",
        "        image_embedding = get_image_embedding(image_url, (224, 224))\n",
        "\n",
        "        if text_embedding is not None and image_embedding is not None:\n",
        "            text_embeddings.append(text_embedding)\n",
        "            image_embeddings.append(image_embedding)\n",
        "            labels.append(label)\n",
        "\n",
        "    return np.array(text_embeddings), np.array(image_embeddings), labels"
      ],
      "metadata": {
        "id": "aeamkGaD3sT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting embeddings and labels for training and testing sets"
      ],
      "metadata": {
        "id": "algcDzyJOJTq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_text_embeddings, train_image_embeddings, train_labels = get_text_embeddings_image_embeddings_labels(train_data)\n",
        "test_text_embeddings, test_image_embeddings, test_labels = get_text_embeddings_image_embeddings_labels(test_data)"
      ],
      "metadata": {
        "id": "WvFOnyrMe31r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "outputId": "a5062e3c-689e-472b-dddd-3a03232c1b65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-ceed0dbb4e22>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_text_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_image_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_text_embeddings_image_embeddings_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_text_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_image_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_text_embeddings_image_embeddings_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Keras to define a neural network model to process text and image embeddings\n"
      ],
      "metadata": {
        "id": "PNvfyB4nOcb_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_input = layers.Input(shape=(train_text_embeddings.shape[1],))\n",
        "text_layer = layers.Dense(128, activation='swish')(text_input)\n",
        "\n",
        "image_input = layers.Input(shape=(224, 224, 3))\n",
        "image_layer = layers.Conv2D(64, (3, 3), activation='swish')(image_input)\n",
        "image_layer = layers.MaxPooling2D((2, 2))(image_layer)\n",
        "image_layer = layers.Flatten()(image_layer)\n",
        "\n",
        "merged = layers.concatenate([text_layer, image_layer])\n",
        "output = layers.Dense(1, activation='sigmoid')(merged)\n",
        "\n",
        "train_labels = np.array(train_labels)\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "model = tf.keras.Model(inputs=[text_input,  image_input], outputs=output)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "mHrwQeXb1mE4",
        "outputId": "f5d79fc7-dcff-4c97-d453-8a06b6769433"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-03e94cdaff95>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtext_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_text_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtext_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'swish'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimage_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimage_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'swish'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_text_embeddings' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the model"
      ],
      "metadata": {
        "id": "1YDBnm1AP3on"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit([train_text_embeddings, train_image_embeddings], train_labels, epochs=5, batch_size=32, validation_split=0.2)"
      ],
      "metadata": {
        "id": "Ddr79hC_P84j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating the model\n"
      ],
      "metadata": {
        "id": "m5deQ3k0P-m8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = model.evaluate([test_text_embeddings, test_image_embeddings], test_labels)\n",
        "print(f'Test Accuracy: {accuracy[1]*100:.2f}%')"
      ],
      "metadata": {
        "id": "KqiimtjeQGv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicting and generating a confusion matrix"
      ],
      "metadata": {
        "id": "s-6s9aK2QJru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict([test_text_embeddings, test_image_embeddings])\n",
        "predicted_labels = (predictions > 0.5).astype(int)\n",
        "confusion_matrix = confusion_matrix(test_labels, predicted_labels)\n",
        "plt.figure(figsize=(10, 10))\n",
        "sea.heatmap(confusion_matrix, annot=True, fmt='d', cmap='Greens', xticklabels=[1,5],yticklabels=[1,5])\n",
        "plt.title('Confusion Matrix - GPT')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Truth')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QR-VoHA7QRf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating Classification Report"
      ],
      "metadata": {
        "id": "zf-U4JmFM1U4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "report_gpt = classification_report(test_labels, predicted_labels)\n",
        "print (f'\\nClassification Report - GPT\\n {report_gpt}')"
      ],
      "metadata": {
        "id": "gj-cQS25MOG-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}